{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import math as m\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "#import torchvision\n",
    "from torchvision import transforms\n",
    "#from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "#from focal_loss import FocalLoss\n",
    "#from models.resnet_me import ResNet\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device_ids=[0]        \n",
    "#TEST\n",
    "from models.SENet.se_resnet import se_resnet18,se_resnet34,se_resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): SEBasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=4, out_features=64, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): SEBasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=4, out_features=64, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): SEBasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEBasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=8, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=8, out_features=128, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): SEBasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEBasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=256, out_features=16, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=16, out_features=256, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): SEBasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SEBasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn1): SwitchNorm2d()\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (sn2): SwitchNorm2d()\n",
      "      (se): SELayer(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=32, bias=True)\n",
      "          (1): ReLU(inplace)\n",
      "          (2): Linear(in_features=32, out_features=512, bias=True)\n",
      "          (3): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (fc): Linear(in_features=512, out_features=16, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = se_resnet18(16)  \n",
    "\n",
    "if use_gpu and len(device_ids)>1:#多gpu训练\n",
    "    model = model.cuda(device_ids[0])\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)\n",
    "if use_gpu and len(device_ids)==1:#单gpu训练\n",
    "    model = model.cuda()\n",
    "print(model)  \n",
    "#print(summary(model,input_size = (3,64,64)))\n",
    "#加载数据\n",
    "\n",
    "# test_file = h5py.File('/home/zj/senetial/data/round2_test_a_20190121.h5', 'r')\n",
    "# test_sen1 = test_file['sen1']\n",
    "# test_sen2 = test_file['sen2']\n",
    "# count=test_sen1.shape[0]\n",
    "# print(count)\n",
    "\n",
    "#加载模型\n",
    "pretained_model = torch.load('/home/zj/senetial/save_models/SENet34/SENet34_96.pth')\n",
    "model.load_state_dict(pretained_model)\n",
    "\n",
    "# batchsize=128\n",
    "# #保存结果\n",
    "# f=open('/home/zj/senetial/data/SENet101_SNA_07_0.9805.csv','w')\n",
    "# for i in tqdm(range(int(math.ceil(float(count)/batchsize)))):###不用管这里到底能不能整除，你进行向上取整就好\n",
    "#     onehot = np.zeros((batchsize,17),dtype=int)\n",
    "#     images=mean_std(AddFeatures(np.concatenate((test_sen1[i*batchsize:(i+1)*batchsize,:,:,:],test_sen2[i*batchsize:(i+1)*batchsize,:,:,:]),axis=3)))#列表：可以自动识别是否到了最后\n",
    "#     inputs = Variable((torch.from_numpy(images)).float().permute(0, 3, 1, 2).cuda(device_ids[0]))\n",
    "#     #print model\n",
    "#     outputs = model(inputs)\n",
    "#     scores, preds = torch.max(outputs.data, 1)#preds\n",
    "#     for i in range(inputs.shape[0]):#注意这里不能用batchsize，只能用列表[:]后的shape\n",
    "#         onehot[i,preds[i]]=1\n",
    "#         f.writelines(','.join(map(str,onehot[i]))+'\\n')\n",
    "#         #f.writelines(','.join(map(str,onehot[i]))+','+str(scores[i])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001752\n",
      "2097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([], shape=(0, 5), dtype=float32),\n",
       "       array([[7.3562317e+02, 2.1623064e+02, 7.6431018e+02, 2.3472412e+02,\n",
       "        9.9878067e-01],\n",
       "       [7.0995581e+02, 2.3365616e+02, 7.6476361e+02, 2.8597391e+02,\n",
       "        9.9888092e-01],\n",
       "       [6.6730133e+02, 3.1940390e+02, 6.8176855e+02, 3.3179498e+02,\n",
       "        1.6012287e-01]], dtype=float32),\n",
       "       array([[5.75149414e+02, 3.48011108e+02, 6.18042725e+02, 3.83258911e+02,\n",
       "        9.90883291e-01],\n",
       "       [7.67795349e+02, 3.54260681e+02, 8.98865173e+02, 4.48436462e+02,\n",
       "        9.98512208e-01],\n",
       "       [6.00091675e+02, 3.54008057e+02, 6.92218018e+02, 4.32637299e+02,\n",
       "        9.98820364e-01],\n",
       "       [6.98875244e+02, 3.46846893e+02, 7.08746338e+02, 3.55391418e+02,\n",
       "        2.19959572e-01],\n",
       "       [6.45518677e+02, 3.45452515e+02, 6.62940125e+02, 3.56026581e+02,\n",
       "        1.11476645e-01]], dtype=float32),\n",
       "       array([], shape=(0, 5), dtype=float32),\n",
       "       array([], shape=(0, 5), dtype=float32),\n",
       "       array([], shape=(0, 5), dtype=float32),\n",
       "       array([], shape=(0, 5), dtype=float32),\n",
       "       array([[6.7598169e+02, 3.4295554e+02, 6.8710156e+02, 3.5717087e+02,\n",
       "        5.0701808e-02],\n",
       "       [6.9697766e+02, 3.4658847e+02, 7.0861292e+02, 3.5539413e+02,\n",
       "        5.9830930e-02]], dtype=float32),\n",
       "       array([], shape=(0, 5), dtype=float32),\n",
       "       array([], shape=(0, 5), dtype=float32)], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10类的结果\n",
    "dets = mmcv.load('/home/zj/mmdetection-swtx/work_dirs/cascade_rcnn_dconv_c3-c5_r50_fpn_1x/result_18.pkl')\n",
    "new_dets = dets\n",
    "#图片读取路径\n",
    "f = open('/home/zj/mmdetection-swtx/data/VOCdevkit/VOC2007/ImageSets/Main/test (复件).txt','r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "print(lines[0][:-1])\n",
    "test_root = '/home/zj/mmdetection-swtx/data/VOCdevkit/VOC2007/JPEGImages'\n",
    "print(len(new_dets))\n",
    "new_dets = np.asarray(new_dets)\n",
    "new_dets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/zj/mmdetection-swtx/data/VOCdevkit/VOC2007/JPEGImages/\\n/.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1c01fbb09c08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlen_class0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen_class0\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_dets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/zj/mmdetection-swtx/data/VOCdevkit/VOC2007/JPEGImages/\\n/.jpg'"
     ]
    }
   ],
   "source": [
    "# 首先需要解析结果，将0类的，再次输入给后续的分类，然后重新更改此处的分类，为其他的分类然后+1，其他的所有的都加16\n",
    "for i in range(len(new_dets)):\n",
    "    \n",
    "    len_class0 = len(new_dets[i][0])\n",
    "    if len_class0!=0:\n",
    "        img = Image.open(os.path.join(test_root,lines[i][-1],'.jpg'))\n",
    "        for x1,y1,x2,y2,s in new_dets[i][0]:\n",
    "            cropped = img.crop((x1,y1,x2,y2))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1,x2,y2,score = new_dets[0][1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB4AAAATCAIAAAAIzCorAAAE0UlEQVR4nAXBS29eVxUG4Hdd9j7f1f7s2Lk0F5MIlOI0adUKIoRACAFDxAD1ZzHhHzBixggEAyoGVBWEZgCEpnUTN8E4zc12fDnfOfvstRbPQ7/9tHfKDCRBX3olhrC5B5MFAIgIEVEgIsyMmYnIwjnLEHBGrUWTSISXIREaVi+mklU19Q4nFHITBAPwPE5BwIDBLWAICBEHlCCEPtzcazEwSTCDaKhkNVFwjSDPSbu+VTPLogNisIEa7nyotSb3IJYsg7kjAGciDaIKBTp1CphZ1BpmjKAwhNdasqZhGCazaTCrEqMaJ3ToD9vT46Edz+YRvTlUsidQZhLRJGNSdlagtT5rIhemHNXAsKhEETHp4OQTShNfDgogJ27tNK2P2vb4jft+HC6HmprpydlZJavsJYZSK2p4b1RhvhTiWkqYO4yTlLDgMDMBNT1urF386e3vKTwKlqZuk/jo7598zctlFoMM5qJqDMsYUC1cQzCAncNOsiiqMwBmr95GdWVXim5Y1/FqY7HCKiJD7atY0fS8PzwY+ZIEmpxZOSpZRAyoEaEh5MQG4cHDBEHVG9beq3KtlEIESksrrfdIULOY5NSKnw19Ja/iVal6SdxUK0EOgGBKnAAiF8hIeX08uzRf25ysLCaz4+Pj/YOXL/rT16XrI3KQJm4DmiiWNYQxDsydas16XGnCR3JYs4nLvGtQYSOS6DZP6nfXr314587Vzbfm0oRHCBk6WFkuz+7tPvrN/Y+fz6clihPUGIXEsphCEjT6dZG3NjYefPUiZjlJWhuPEvSoO6Ey/OTO+x/e+sEFnIyhhppEX5eehddkdm42G99e1M3Fr/70ezHLgDrTENIOtQZsaN99+5u3t65fXpx7fHHj/qOHP/vxz18cvFqZre7tP3nxePeXt97fQjTwJ892ZLrep/GX+89X57Ob5zZWRS+g+f7Fm/94+/GzYlGdBZQlZ5bouqnjQjPe3rx8M6398Mr2zWZj5vHPv/7t5Ze7W/PFd65uXUWzKEtCna/O/3f4qh8393a/uLfzeYhagMuwivhga2u87CZuGoEs3BWbhMwkr84We3uvNq98a+/p3mLlcsTonffubl278uZgnwOEaPLYgOlElU7K2cnd994daWqHpWtDQga8/PoVldoQq7t3Q2Vmc2p7PzKZX77w6dnZ+Or13X8dHbx+8/jg9U57mLycd+yDCDSBc/Cs+jmWV7tf6XR6fvtWBc4k79jxXx58MVpsNknUyQYN1kTilpuPPvt3+2hXuald7+S2v1OiippaOU95Md350fVvX4NOabR9Y5vhlz64C6IeOAI9QfvrP//xaZLr08VBB2XBoASvZlYRL8vZUcOIggZNmFsBO1PknF4a/+Gzh89O6BfvfGPKmAIjcGKuwCns490Hv7v/yX8lThte8340gmpIZgpnFc4co0ygDkwQ8b5TdndnIgtpKe/X9s3u5/95+nCxWFmsrDZgK33bnr44OXh+etCOpWuE3FGXCdAA07ISuZUyYZq5rUQszXjZN4FEqB7u5GBnX5IPRC2RvWn96DmDAESEx8BNQpi17URkVdEAWgVjcAWbe0M0KcO0DKujhirEXURKoFo4KkQqPFA9Ak4SLOAgYU2jPJmnlGqdj1IGbqxcogH/BwDAB3gSAr10AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=30x19 at 0x7F52E6F3CDA0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(os.path.join(test_root,'001752.jpg'))\n",
    "x1,y1,x2,y2,score = new_dets[0][1][0]\n",
    "#cropped = img.crop((x1,y1,x2,y2))\n",
    "cropped = img.crop((m.floor(x1),m.floor(y1),m.ceil(x2),m.ceil(y2)))\n",
    "cropped.save('./1.jpg')\n",
    "#np.asarray(cropped).shape\n",
    "cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join(test_root,'001752.jpg'))\n",
    "x1,y1,x2,y2,score = new_dets[0][1][0]\n",
    "cropped = img[m.floor(y1):m.ceil(y2),m.floor(x1):m.ceil(x2),:]\n",
    "#cropped = img.crop((m.floor(x1),m.floor(y1),m.ceil(x2),m.ceil(y2)))\n",
    "cv2.imwrite('./2.jpg',cv2.resize(cropped,(64,64)))\n",
    "#np.asarray(cropped).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([735.62317   , 216.23064   , 764.3102    , 234.72412   ,\n",
       "         0.99878067], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
