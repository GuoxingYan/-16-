{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "\"\"\"\n",
    "Created on Thu Dec  6 21:58:01 2018\n",
    "\n",
    "@author: zj\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Dec  4 17:33:44 2018\n",
    "原先愚蠢的认为都读到内存再打乱，可惜了h5文件太大了\n",
    "@author: ygx\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "#from focal_loss import FocalLoss\n",
    "from models.resnet_me import ResNet\n",
    "from models.resnet_v2_sn import resnetv2sn18\n",
    "#多gpu训练\n",
    "device_ids = [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddFeatures(array):\n",
    "    \"\"\"\n",
    "    输入一个18个波段的concat之后的图像NHWC\n",
    "    NDVI、SI阴影指数、ndbi建筑物指数\n",
    "    \"\"\"\n",
    "    ndvi=(array[:,:,:,14]-array[:,:,:,11])/(array[:,:,:,14]+array[:,:,:,11])\n",
    "    si=(array[:,:,:,14]+array[:,:,:,9]+array[:,:,:,11]+array[:,:,:,10])/4\n",
    "    ndbi=(array[:,:,:,17]-array[:,:,:,14])/(array[:,:,:,17]+array[:,:,:,14])\n",
    "    output=np.concatenate((array,ndvi,si,ndbi),axis=3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self,\n",
    "                 filepath='/home/zj/senetial/data',\n",
    "                 batch_size=256,\n",
    "                 datatype='train',\n",
    "                 split=0.1):\n",
    "        train_file = h5py.File(os.path.join(filepath, 'training.h5'), 'r')\n",
    "        val_file = h5py.File(os.path.join(filepath, 'validation.h5'), 'r')\n",
    "        test_file = h5py.File('/home/zj/senetial/data/round1_test_a_20181109.h5', 'r')\n",
    "        self.train_X1 = train_file['sen1']\n",
    "        self.train_X2 = train_file['sen2']\n",
    "        self.train_Y = train_file['label']\n",
    "\n",
    "        self.val_X1 = val_file['sen1']\n",
    "        self.val_X2 = val_file['sen2']\n",
    "        self.val_Y = val_file['label']\n",
    "\n",
    "        self.test_sen1 = test_file['sen1']\n",
    "        self.test_sen2 = test_file['sen2']\n",
    "\n",
    "\n",
    "        # 统计每一个数据集的数量\n",
    "        self.num_train = self.train_Y.shape[0]\n",
    "        self.num_val = self.val_Y.shape[0]\n",
    "        # 按照batch_size进行（分组）采样\n",
    "        # 得到每一个分组的索引 [0, 8, 16, 24, ...]\n",
    "        num_groups = int((self.num_train + self.num_val) / batch_size)\n",
    "        self.indices = np.arange(num_groups) * batch_size#这里其实少了最后面的一个batch，但是就不用考虑train和val中间的情况\n",
    "        #np.random.seed(1)\n",
    "        np.random.seed(2)\n",
    "        np.random.shuffle(self.indices)\n",
    "        # 这里只选择总数的后1/10作为验证集\n",
    "        # 其余的作为训练集\n",
    "        split = int(num_groups * split)\n",
    "        split = -split if split else None\n",
    "        if datatype == 'train':\n",
    "            self.indices = self.indices[:split]\n",
    "        else:\n",
    "            self.indices = self.indices[split:]\n",
    "        #count是指示的总数/batchsize\n",
    "        self.count = self.indices.size\n",
    "        self.batch_size = batch_size\n",
    "        self.index = 0\n",
    "\n",
    "    def next_batch(self, batch_size=16):\n",
    "        idx = self.indices[self.index]\n",
    "        if idx > self.num_train:\n",
    "            idx = idx - self.num_train\n",
    "            X1 = self.val_X1\n",
    "            X2 = self.val_X2\n",
    "            Y = self.val_Y\n",
    "        else:\n",
    "            X1 = self.train_X1\n",
    "            X2 = self.train_X2\n",
    "            Y = self.train_Y\n",
    "        images_1 = X1[idx:idx + batch_size]\n",
    "        images_2 = X2[idx:idx + batch_size]\n",
    "        labels = Y[idx:idx + batch_size]\n",
    "\n",
    "        self.index += 1\n",
    "        if self.index >= self.count:\n",
    "            self.index = 0\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        images_1 = np.asarray(images_1, dtype=np.float32)\n",
    "        images_2 = np.asarray(images_2, dtype=np.float32)#(352366, 32, 32, 10)\n",
    "        labels = np.asarray(labels, dtype=np.float32)\n",
    "        images=np.concatenate((images_1,images_2),axis=3)#合并归一化操作#(352366, 32, 32, 18)\n",
    "        \n",
    "        #images = mean_std(AddFeatures(images))        \n",
    "        #images=RandomPaddingCrop(RandomFlip(images))\n",
    "        \n",
    "        return images, labels\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next_batch(self.batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Test        \n",
    "\n",
    "#test_file = h5py.File('/home/zj/senetial/data/round1_test_a_20181109.h5', 'r')\n",
    "#test_file = h5py.File('/home/zj/senetial/data/validation.h5','r')\n",
    "#test_sen1 = test_file['sen1']\n",
    "#test_sen2 = test_file['sen2']\n",
    "#count=test_sen1.shape[0]\n",
    "\n",
    "#测试一下时间\n",
    "start=time.time()\n",
    "\n",
    "#计算方11011\n",
    "mean,std=0,0\n",
    " #前30000个均值，方差\n",
    "#train\n",
    "train = Generator()\n",
    "datas_train,_= train.__next__()#一次跑出batchsize张 32\n",
    "mean =np.mean(datas_train,axis=(0,1,2))\n",
    "std=np.std(datas_train,axis=(0,1,2))\n",
    "####test\n",
    "#images=(np.concatenate((test_sen1[:,:,:,:],test_sen2[:,:,:,:]),axis=3))#列表：可以自动识别是否到了最后\n",
    "#print images.shape\n",
    "#mean =np.mean(images,axis=(0,1,2))\n",
    "#std=np.std(images,axis=(0,1,2))\n",
    "#    \n",
    "print '_'*60\n",
    "print mean\n",
    "print '_'*60\n",
    "print std \n",
    "print '_'*60\n",
    "end=time.time()\n",
    "print end-start #100次1.14秒\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
