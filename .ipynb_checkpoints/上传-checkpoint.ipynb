{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import math as m\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "#import torchvision\n",
    "from torchvision import transforms\n",
    "#from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "#from focal_loss import FocalLoss\n",
    "#from models.resnet_me import ResNet\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device_ids=[0]        \n",
    "#TEST\n",
    "from models.senet import SENet18,SENet34,SENet101,SENet152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SENet34()  \n",
    "if use_gpu and len(device_ids)>1:#多gpu训练\n",
    "    model = model.cuda(device_ids[0])\n",
    "    model = nn.DataParallel(model, device_ids=device_ids)\n",
    "if use_gpu and len(device_ids)==1:#单gpu训练\n",
    "    model = model.cuda()\n",
    "    \n",
    "print(model)\n",
    "#加载数据\n",
    "\n",
    "test_file = h5py.File('/home/zj/senetial/data/round2_test_a_20190121.h5', 'r')\n",
    "test_sen1 = test_file['sen1']\n",
    "test_sen2 = test_file['sen2']\n",
    "count=test_sen1.shape[0]\n",
    "print(count)\n",
    "\n",
    "#加载模型\n",
    "pretained_model = torch.load('/home/zj/senetial/save_models/SENet34/SENet34_96.pth')\n",
    "model.load_state_dict(pretained_model)\n",
    "\n",
    "batchsize=128\n",
    "#保存结果\n",
    "f=open('/home/zj/senetial/data/SENet101_SNA_07_0.9805.csv','w')\n",
    "for i in tqdm(range(int(math.ceil(float(count)/batchsize)))):###不用管这里到底能不能整除，你进行向上取整就好\n",
    "    onehot = np.zeros((batchsize,17),dtype=int)\n",
    "    images=mean_std(AddFeatures(np.concatenate((test_sen1[i*batchsize:(i+1)*batchsize,:,:,:],test_sen2[i*batchsize:(i+1)*batchsize,:,:,:]),axis=3)))#列表：可以自动识别是否到了最后\n",
    "    inputs = Variable((torch.from_numpy(images)).float().permute(0, 3, 1, 2).cuda(device_ids[0]))\n",
    "    #print model\n",
    "    outputs = model(inputs)\n",
    "    scores, preds = torch.max(outputs.data, 1)#preds\n",
    "    for i in range(inputs.shape[0]):#注意这里不能用batchsize，只能用列表[:]后的shape\n",
    "        onehot[i,preds[i]]=1\n",
    "        f.writelines(','.join(map(str,onehot[i]))+'\\n')\n",
    "        #f.writelines(','.join(map(str,onehot[i]))+','+str(scores[i])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001752\n"
     ]
    }
   ],
   "source": [
    "#10类的结果\n",
    "dets = mmcv.load('/home/zj/mmdetection-swtx/work_dirs/cascade_rcnn_dconv_c3-c5_r50_fpn_1x/result_18.pkl')\n",
    "new_dets = dets\n",
    "#图片读取路径\n",
    "f = open('/home/zj/mmdetection-swtx/data/VOCdevkit/VOC2007/ImageSets/Main/test (复件).txt','r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "print(lines[0][:-1])\n",
    "test_root = '/home/zj/mmdetection-swtx/data/VOCdevkit/VOC2007/JPEGImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先需要解析结果，将0类的，再次输入给后续的分类，然后重新更改此处的分类，为其他的分类然后+1，其他的所有的都加16\n",
    "for i in range(len(new_dets)):\n",
    "    \n",
    "    len_class0 = len(new_dets[i][0])\n",
    "    if len_class0!=0:\n",
    "        img = Image.open(os.path.join(test_root,lines[i][-1],'.jpg'))\n",
    "        for x1,y1,x2,y2,s in new_dets[i][0]:\n",
    "            cropped = img.crop((x1,y1,x2,y2))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1,x2,y2,score = new_dets[0][1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(os.path.join(test_root,'001752.jpg'))\n",
    "x1,y1,x2,y2,score = new_dets[0][1][0]\n",
    "cropped = img.crop((x1,y1,x2,y2))\n",
    "#cropped = img.crop((m.floor(x1),m.floor(y1),m.ceil(x2),m.ceil(y2)))\n",
    "cropped.save('./1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([735.62317   , 216.23064   , 764.3102    , 234.72412   ,\n",
       "         0.99878067], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
